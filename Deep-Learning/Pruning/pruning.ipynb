{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils import prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version : 1.13.1\n",
      "CUDA version : 11.7\n"
     ]
    }
   ],
   "source": [
    "print(f'PyTorch version : {torch.__version__}\\n'\n",
    "      f'CUDA version : {torch.cuda_version}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weight', 'bias'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(100, 200)\n",
    "\n",
    "params = dict(fc.named_parameters())\n",
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffers = dict(fc.named_buffers())\n",
    "buffers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=100, out_features=200, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prune.l1_unstructured(fc, 'weight', 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['bias', 'weight_orig'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = dict(fc.named_parameters())\n",
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['weight_mask'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffers = dict(fc.named_buffers())\n",
    "buffers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000, -0.0989,  ...,  0.0000, -0.0883, -0.0000],\n",
       "        [-0.0798,  0.0000, -0.0627,  ...,  0.0577,  0.0769, -0.0962],\n",
       "        [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0555],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0773,  ...,  0.0000, -0.0000, -0.0576],\n",
       "        [-0.0786,  0.0535, -0.0599,  ...,  0.0660,  0.0000, -0.0654],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0620, -0.0000]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([(0, <torch.nn.utils.prune.L1Unstructured at 0x202483f4c40>)])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc._forward_pre_hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1987,  1.2184, -0.0000,  ...,  0.7120, -0.0000, -0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.8938,  2.0662],\n",
       "        [-1.0300,  0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
       "        ...,\n",
       "        [-1.0800, -0.8545,  0.0000,  ..., -0.0000, -1.2614,  0.8715],\n",
       "        [-0.7051,  0.0000,  1.0982,  ...,  1.4157, -1.0476,  0.0000],\n",
       "        [ 0.0000,  0.7177,  0.0000,  ..., -0.7013, -0.0000,  0.0000]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.randn(100, 200)\n",
    "\n",
    "l1_unstructured = prune.L1Unstructured(0.5)\n",
    "pruned_tensor = l1_unstructured.prune(random_tensor)\n",
    "\n",
    "pruned_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1UnstructuredPartitioned(prune.L1Unstructured):\n",
    "\n",
    "    def __init__(self, amount, npartitions):\n",
    "        super(L1UnstructuredPartitioned, self).__init__(amount)\n",
    "        self.npartitions = npartitions\n",
    "\n",
    "\n",
    "    def compute_mask(self, t, default_mask):\n",
    "        t_partitions = torch.split(t, t.shape[0] // self.npartitions, dim=0)\n",
    "        default_mask_partitions = torch.split(\n",
    "            default_mask, default_mask.shape[0] // self.npartitions, dim=0\n",
    "        )\n",
    "        mask_partitions = [\n",
    "            super(L1UnstructuredPartitioned, self).compute_mask(t_p, dm_p)\n",
    "            for t_p, dm_p in zip(t_partitions, default_mask_partitions)\n",
    "        ]\n",
    "        return torch.concat(mask_partitions, dim=0)\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def apply(cls, module, name, amount, npartitions, importance_scores=None):\n",
    "        return super(prune.L1Unstructured, cls).apply(\n",
    "            module, name, amount, npartitions, importance_scores=importance_scores\n",
    "        )\n",
    "    \n",
    "\n",
    "\n",
    "def l1_unstructured_partitioned(\n",
    "        module, name, amount, npartitions, importance_scores=None\n",
    "    ):\n",
    "    L1UnstructuredPartitioned.apply(\n",
    "        module,\n",
    "        name,\n",
    "        amount,\n",
    "        npartitions,\n",
    "        importance_scores=importance_scores\n",
    "    )\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=100, out_features=300, bias=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(100, 300)\n",
    "\n",
    "l1_unstructured_partitioned(fc, 'weight', 0.5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 0 sparsity : 0.50\n",
      "Partition 1 sparsity : 0.50\n",
      "Partition 2 sparsity : 0.50\n"
     ]
    }
   ],
   "source": [
    "partitioned_weights = torch.split(fc.weight, int(fc.weight.shape[0] / 3))\n",
    "\n",
    "for idx, partitioned_weight in enumerate(partitioned_weights):\n",
    "    num_units_in_partition = partitioned_weight.nelement()\n",
    "    zeros = (partitioned_weight == 0.).sum()\n",
    "    print(f\"Partition {idx} sparsity : {zeros / num_units_in_partition:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
