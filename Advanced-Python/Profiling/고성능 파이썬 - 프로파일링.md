# 고성능 파이썬 - 프로파일링

날짜: 2023-07-20
작성자: 박진호

# 1. 효과적인 프로파일링

---

- 프로파일할 경우, 10~100배까지 실행속도가 느려짐 → 실제 상황과 유사한 조건에서 테스트하고자 한다면 프로파일할 부분만 따로 떼어내서 테스트
- deterministic profiling
    - 모든 함수 호출, 함수 반환 및 예외 이벤트를 모니터링하여, 이벤트 사이의 간격(사용자 코드가 실행되는 시간)도 정확히 측정 가능
    - 모든 이벤트를 모니터링 하기 때문에 오버드가 큼
- statistical profiling (sampling profiling)
    - 무작위 샘플링을 통해 어떤 코드 시간을 사용하는 중인지 추론 가능
    - 코드를 계측하고 있지 않으므로 오버헤드가 적지만 사용된 시간의 상대적인 양만 확인할 수 있음.
        
        

# 2. 시간 측정 방법

---

## 1) IPython timeit, time 매직 명령어

<aside>
💡 매직 명령어를 사용하기 위해서는 명령어 앞에 %를 입력해야 함.
%: Line 매직 명령어,  %%: Cell 매직 명령어

</aside>

- %time
    
    코드 한 줄 실행 시간 출력
    
- %%time
    
    cell 하나 실행 시간 출력
    
- timeit
    
    코드를 반복 수행한 후 평균 실행 시간과 표준편차 출력
    
    -n <N> : 코드를 루프에서 N번 실행(지정하지 않을 경우, 높은 정확도를 위해 충분히 많이 반복)
    
    -r <R> : 루프 반복 당 시간 측정 횟수
    
    ```python
    %time fft_img = np_fft_2d(image_h)
    
    ''' 출력 결과
    CPU times: user 28.6 ms, sys: 1.95 ms, total: 30.6 ms    # CPU가 코드를 수행한 시간
    Wall time: 29.4 ms                                       # 실제 수행 시간
    '''
    ```
    
    ```python
    %%timeit
    ifft_img = np_ifft_2d(fft_img)
    
    ''' 출력 결과
    27.9 ms ± 759 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)
    '''
    ```
    

## 2) time 모듈 (print, decorator)

- time.time() → float

1970년 1월 1일 00:00:00부터의 경과시간을 초(s) 단위로 반환 (real-world time)

- time.time_ns() → int

1970년 1월 1일 00:00:00부터의 경과시간을 나노 초(ns) 단위로 반환 (real-world time)

- time.process_time() → float

sleep과 pending을 제외한 코드의 연산 시간만 측정 [s] (relative time)

- time.perf_counter() → float

sleep, file I/O(pending)에 소요되는 시간을 포함한 연산 시간 [s] (relative time)

- print문 사용
    
    시간 측정이 간단하지만 코드 가독성을 떨어트림.
    
    ```python
    import time
    
    image = np.random.randn(5000,5000)
    
    start = time.time()
    fft_img = np_fft_2d(image)      # 시간을 측정할 코드 [s]
    end = time.time()
    print(f"{end - start:.5f} sec")
    
    start = time.time()
    ifft_img = np_ifft_2d(fft_img)
    end = time.time()
    print(f"{end - start:.5f} sec")
    ```
    
- decorator 사용 (파이썬에 함수나 메서드를 수정/확장하기 위한 기능)
    
    함수 호출보다는 오버헤드가 낮지만 차이가 크지 않음.
    
    ```python
    from functools import wraps   # 함수의 메타데이터(이름, 독스트링 등)를 보존하기 위해 사용
    
    # decorator 정의
    def timefn(fn):   # decorator로 감쌀 함수를 인자 받음.  
        @wraps(fn)
        def measure_time(*args, **kwargs):
            start = time.time()
            result = fn(*args, **kwargs)
            end = time.time()
            print(f"{end - start:.5f} sec")
            return result
        return measure_time
    ```
    
    ```python
    # 사용법 1 (함수 정의)
    @timefn
    def np_fft_2d_time(img):
        fft_img = np.fft.fft2(img)
        shifted_img = np.fft.fftshift(fft_img)
        return shifted_img
    
    # 사용법 2 (이미 정의된 함수)
    np_ifft_2d_time = timefn(np_ifft_2d)
    ```
    

![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled.png)

<aside>
⚠️ **GPU를 사용할 때 시간 측정 방법**
CPU와 GPU는 Asynchronous로 동작하기 때문에 CPU 시간을 측정하는 perf_counter, %timeit으로는 GPU 실행 시간 측정할 수 없음. **(Sync 필요)**

</aside>

![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled.jpeg)

### CuPy 시간 측정 방법

- CUDA Event 사용 ([링크](https://docs.cupy.dev/en/latest/reference/generated/cupy.cuda.Event.html))
    
    ```python
    import cupy as cp
    
    start_gpu = cp.cuda.Event()
    end_gpu = cp.cuda.Event()
    
    start_gpu.record()
    out = my_func(arg)      # GPU 연산 시간 측정 
    end_gpu.record()
    end_gpu.synchronize()   # GPU 연산이 끝날 때까지 대기
    
    t_gpu = cp.cuda.get_elapsed_time(start_gpu, end_gpu) # 밀리초 단위
    ```
    
- CuPy 벤치마크 사용 ([링크](https://docs.cupy.dev/en/stable/user_guide/performance.html))
    
    ```python
    from cupyx.profiler import benchmark        # 함수 시간(CPU, GPU) 측정
    img_size = 1000
    image_d = cp.random.randn(img_size,img_size)
    
    print(benchmark(cp_fft_2d, (image_d,), n_repeat=20))  # 벤치마크할 함수
    
    ''' 출력 결과
    cp_fft_2d :    
    CPU:  331.201 us   +/-71.646 (min:  280.851 / max:  528.970) us     
    GPU-0: 3519.526 us   +/-21.491 (min: 3500.064 / max: 3581.472) us
    '''
    ```
    

### Pytorch 시간 측정 방법

[https://deci.ai/blog/measure-inference-time-deep-neural-networks/](https://deci.ai/blog/measure-inference-time-deep-neural-networks/) 

```python
import torch 

model = EfficientNet.from_pretrained('efficientnet-b0')
device = torch.device("cuda")
model.to(device)
dummy_input = torch.randn(1, 3,224,224, dtype=torch.float).to(device)

# INIT LOGGERS
starter, ender = **torch.cuda.Event**(enable_timing=True), torch.cuda.Event(enable_timing=True)

#GPU-WARM-UP
for _ in range(100):
    _ = model(dummy_input)

# MEASURE PERFORMANCE
with torch.no_grad():
    for rep in range(repetitions):
        starter.record()
        _ = model(dummy_input)
        ender.record()
        # WAIT FOR GPU SYNC
        **torch.cuda.synchronize()**
        curr_time = starter.elapsed_time(ender)
        timings[rep] = curr_time
```

## 3) 유닉스 time 명령어

- 사용 방법
    
    `$ /usr/bin/time -p python numpy_fft_ifft.py   # 시스템의 time 명령어`
    
    `$ time -p python numpy_fft_ifft.py            # shell에 포함된 time (덜 유용한 버전)` 
    
- 출력 결과

![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%201.png)

# -p 옵션
# real: 명령어가 호출부터 종료될 때까지 소요된 시간 (I/O 대기시간 포함)
# user: CPU가 커널 함수 외 작업을 처리할 때 소비한 시간
# sys: 커널 함수를 수행하는 데 소비한 시간 (File 접근, I/O 관리, 메모리 접근 등을 위한 system call)

# 3. CProfile (SnakeViz 시각화) - CPU 사용량

---

`[cProfile](https://docs.python.org/ko/3/library/profile.html#module-cProfile)`과 `[profile](https://docs.python.org/ko/3/library/profile.html#module-profile)`은 파이썬 프로그램의 결정론적 프로파일링 (deterministic profiling)을 제공한다. 

- 파이썬 스크립트 파일 프로파일링 방법
    
    ```bash
    # 사용 방법
    python -m cProfile [옵션] [프로파일링할 .py 파일]
    
    # 옵션
    #  -s cumulative: 각 함수에서 소요 시간을 누적 시간 순으로 내림차순 정렬 ([추가 옵션](https://docs.python.org/ko/3.8/library/profile.html#pstats.Stats.sort_stats))
    #  -s calls: 호출 수 순으로 내림차순 정렬
    #  -o [통계 파일명.stats] : 프로파일링 통계 파일 저장
    ```
    
- cProfile 모듈 사용법
    
    ```python
    import cProfile
    
    cProfile.run('[프로파일링할 함수]')
    
    ''' 출력 예시
    197 function calls (192 primitive calls) in 0.002 seconds -> 192회 호출(재귀 호출 0회)
    
    Ordered by: standard name
    
    ncalls  tottime  percall  cumtime  percall  filename:lineno(function)
         1    0.000    0.000    0.001    0.001  <string>:1(<module>)
         1    0.000    0.000    0.001    0.001  re.py:212(compile)
         1    0.000    0.000    0.001    0.001  re.py:268(_compile)
         1    0.000    0.000    0.000    0.000  sre_compile.py:172(_compile_charset)
         1    0.000    0.000    0.000    0.000  sre_compile.py:201(_optimize_charset)
         4    0.000    0.000    0.000    0.000  sre_compile.py:25(_identityfunction)
       3/1    0.000    0.000    0.000    0.000  sre_compile.py:33(_compile)
    '''
    
    # 프로파일링 결과 저장
    cProfile.run('[프로파일링할 함수]', '[프로파일링 결과 저장 파일명]')
    
    import pstats
    from pstats import SortKey
    p = pstats.Stats('restats')
    p.strip_dirs().sort_stats(-1).print_stats() # strip_dirs(): 모듈 이름에서 외부 경로를 제거
                                                # print_stats(N): N개의 줄 출력
                                                # sort_stats(정렬 방법): 정렬 방법 설정
    ```
    
- 출력 결과 해석
    - `ncalls` : 호출 횟수 (total invocation / primitive or non-recursive call)
    - `tottime` : 주어진 함수에서 소비된 총 시간
    - `percall` : `tottime`을 `ncalls`로 나눈 몫
    - `cumtime` : 이 함수와 모든 서브 함수에서 소요된 누적 시간 (재귀 함수에서도 정확함.)
    - `percall` : `cumtime`을 프리미티브 호출로 나눈 몫
    - `filename:lineno(function)` : 파일명:줄 번호(함수)
- SnakeViz로 CProfile 결과 시각화
    - 설치 방법
        
        `$ pip install snakeviz`
        
    - 시각화 방법
        
        `$ python -m snakeviz [프로파일링 결과 파일]`
        
    - 시각화 예시
        
        프로램의 진입점을 다이어그램 맨 위에 확인 가능, 아래의 각 계층은 위쪽 함수가 호출한 함수를 보여줌.
        
    
    ![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%202.png)
    
    <aside>
    💡 CProfile로 가장 병목인 함수를 확인할 수 있음. 이후, line_profiler 또는 memory_profiler를 사용하여 해당 함수를 라인 별로 프로파일링
    
    </aside>
    

# 4. line_profiler

---

- 설치 방법

`$ pip install line_profiler`

- 사용 방법
    - 프로파일링할 함수 위에 데코레이터 `@profile` 추가
        
        ```python
        import numpy as np
        
        # Numpy
        @profile
        def np_fft_2d(img):
        	fft_img = np.fft.fft2(img)
        	shifted_img = np.fft.fftshift(fft_img)
        	return shifted_img
        
        @profile
        def np_ifft_2d(fft_img):
        	ishifted_img = np.fft.ifftshift(fft_img)
        	ifft_img = np.fft.ifft2(ishifted_img)
        	return ifft_img
        	
        img_size = 1000
        image_h = np.random.randn(img_size,img_size)
        fft_img = np_fft_2d(image_h)
        ifft_img = np_ifft_2d(fft_img)
        ```
        
    - `$ kernprof -l -v [py 파일명].py`
        - `-l` : 라인 단위 프로파일링
        - `-v` : 프로파일링 결과를 터미널에 출력 (.lprof 파일 저장)
- 실행 결과
    
    ![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%203.png)
    
    Line #: 파일에서 라인 번호
    
    Hits: 해당 라인이 실행된 횟수
    
    Time: 해당 라인을 실행하는 데 소요된 총 시간
    
    Per Hit: 해당 라인을 실행하는 데 소요된 평균 시간
    
    % Time: 함수에 전체 소요 시간에서 해당 라인의 백분율
    
    Line Contents: 라인 번호에 해당하는 소스 코드
    

# 5. 메모리 사용량 프로파일링

---

## 1) IPython memit 매직 명령어

주어진 코드의 메모리 사용량 출력

- 사용 방법
    - memory_profiler 설치
        
        `$ pip install memory_profiler`
        
    - IPython extension load
        
        `%load_ext memory_profiler` 
        
    - 메모리 사용량 확인이 필요한 라인 앞에 `%memit` 추가

## 2) memory_profiler

메모리 사용량을 줄 단위로 측정 (line_profiler 보다 오래 걸림)

전체 프로그램이 종료되어야 결과가 출력되므로 런타임이 긴 프로그램에는 적절하지 않음.

- 설치 방법
    
    `$ pip install memory_profiler`
    
    `$ pip install psutil`
    
- 사용 방법
    - 프로파일링할 함수 위에 데코레이터 `@profile` 추가 (line_profiler 사용법과 동일
        
        ```python
        import numpy as np
        
        # Numpy
        @profile
        def np_fft_2d(img):
        	fft_img = np.fft.fft2(img)
        	shifted_img = np.fft.fftshift(fft_img)
        	return shifted_img
        
        @profile
        def np_ifft_2d(fft_img):
        	ishifted_img = np.fft.ifftshift(fft_img)
        	ifft_img = np.fft.ifft2(ishifted_img)
        	return ifft_img
        	
        img_size = 1000
        image_h = np.random.randn(img_size,img_size)
        fft_img = np_fft_2d(image_h)
        ifft_img = np_ifft_2d(fft_img)
        ```
        
    - `$ python -m memory_profiler [py 파일명].py`
- 실행 결과
    
    ![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%204.png)
    
    Line #: py 파일에서 라인 번호
    
    Mem usage: 파이썬 인터프리터의 메모리 사용량
    
    Increment: 현재 라인과 이전 라인의 메모리 사용량 차이(memory_usage 모듈에 버그 있어서 정확지 않을 수 있음. → Mem usage 사용 추천
    
    Line Contents: 라인 번호에 해당하는 소스 코드
    
- 결과 시각화
    
    운영체제나 Garbage Collection의 영향으로 항상 동일한 결과 출력되지는 않음.
    
    `$ mprof run [py 파일명].py`
    
    `$ mprof plot`
    

![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%205.png)

![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%206.png)

## 3) **tracemalloc ([링크](https://docs.python.org/ko/3/library/tracemalloc.html))**

프로그램 실행 중 메모리 할당과 해제에 대한 세부 정보 수집을 위한 도구

코드의 어느 부분에서 메모리가 할당되는지, 할당된 메모리의 양, 할당 횟수 등을 확인할 수 있음.

- 가장 많은 메모를 할당하는

```python
import tracemalloc

tracemalloc.start()
# ... run your application ...
snapshot = tracemalloc.take_snapshot()
top_stats = snapshot.statistics('lineno')

print("[ Top 10 ]")
for stat in top_stats[:10]:   # 가장 많은 메모리를 할당하는 10개의 파일을 표시
    print(stat)

''' 출력 예시
<__array_function__ internals>:180: size=30.5 MiB, count=4, average=7813 KiB
/usr/local/lib/python3.10/dist-packages/numpy/fft/_pocketfft.py:73: size=30.5 MiB, count=4, average=7813 KiB
<ipython-input-38-5d1d655674c7>:8: size=7813 KiB, count=2, average=3906 KiB
<ipython-input-37-5d1d655674c7>:8: size=7813 KiB, count=2, average=3906 KiB
/usr/lib/python3.10/linecache.py:137: size=1968 KiB, count=19678, average=102 B
/usr/lib/python3.10/tracemalloc.py:558: size=25.7 KiB, count=499, average=53 B
/usr/lib/python3.10/tracemalloc.py:193: size=19.0 KiB, count=406, average=48 B
/usr/lib/python3.10/tracemalloc.py:67: size=14.6 KiB, count=234, average=64 B
/usr/lib/python3.10/tracemalloc.py:505: size=13.5 KiB, count=241, average=58 B
/usr/local/lib/python3.10/dist-packages/IPython/core/compilerop.py:101: size=12.3 KiB, count=214, average=59 B
'''
```

```python
import linecache
import os
import tracemalloc

def display_top(snapshot, key_type='lineno', limit=10):
    snapshot = snapshot.filter_traces((
        tracemalloc.Filter(False, "<frozen importlib._bootstrap>"),
        tracemalloc.Filter(False, "<unknown>"),
    ))
    top_stats = snapshot.statistics(key_type)

    print("Top %s lines" % limit)
    for index, stat in enumerate(top_stats[:limit], 1):
        frame = stat.traceback[0]
        print("#%s: %s:%s: %.1f KiB"
              % (index, frame.filename, frame.lineno, stat.size / 1024))
        line = linecache.getline(frame.filename, frame.lineno).strip()
        if line:
            print('    %s' % line)

    other = top_stats[limit:]
    if other:
        size = sum(stat.size for stat in other)
        print("%s other: %.1f KiB" % (len(other), size / 1024))
    total = sum(stat.size for stat in top_stats)
    print("Total allocated size: %.1f KiB" % (total / 1024))

tracemalloc.start()
# ... run your application ...
snapshot = tracemalloc.take_snapshot()
# top_stats = snapshot.statistics('lineno')
display_top(snapshot)

''' 출력 예시
Top 10 lines
#1: /usr/local/lib/python3.10/dist-packages/numpy/fft/_pocketfft.py:73: 31250.2 KiB
    r = pfi.execute(a, is_real, is_forward, fct)
#2: <__array_function__ internals>:180: 15625.2 KiB
#3: <ipython-input-130-442a133a2a97>:32: 7812.6 KiB
    image_h = np.random.randn(img_size,img_size)
#4: /usr/lib/python3.10/linecache.py:137: 711.5 KiB
    lines = fp.readlines()
#5: /usr/local/lib/python3.10/dist-packages/IPython/core/compilerop.py:101: 39.7 KiB
    return compile(source, filename, symbol, self.flags | PyCF_ONLY_AST, 1)
#6: /usr/lib/python3.10/abc.py:123: 31.4 KiB
    return _abc_subclasscheck(cls, subclass)
#7: /usr/lib/python3.10/tracemalloc.py:558: 26.2 KiB
    traces = _get_traces()
#8: /usr/local/lib/python3.10/dist-packages/IPython/core/compilerop.py:159: 19.6 KiB
    [line + "\n" for line in transformed_code.splitlines()],
#9: /usr/local/lib/python3.10/dist-packages/debugpy/_vendored/pydevd/_pydevd_bundle/_debug_adapter/pydevd_base_schema.py:26: 18.6 KiB
    dap_id = BaseSchema._obj_id_to_dap_id[obj_id] = BaseSchema._next_dap_id()
#10: /usr/local/lib/python3.10/dist-packages/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_source_mapping.py:116: 18.0 KiB
    self._cache[key] = False
279 other: 286.2 KiB
Total allocated size: 55839.3 KiB
'''
```

# 6. PySpy

---

Py-spy는 System Call(Linux의 경우 process_vm_readv, OSX의 경우 vm_read, Windows의 경우 ReadProcessMemory)을 사용하여 프로램의 호출 스택 상태를 정기적으로 샘플링하는 방식으로 동작 → 오버헤드 거의 없음.

프로램 전체를 프로파일링하거나 일부 구성 요소(함수, 모듈)를 외부에서 프로파일링할 때, 사용 가능 (특정 함수만 샘플링할 수 없음)

- 설치 방법

`$ pip install py-spy`

- 사용 방법 1 - flame chart로 저장
    
    ```bash
    # 이미 실행 중인 프로그램을 프로파일할 때
    $ sudo env "PATH=$PATH" py-spy record -o profile.svg --pid [프로파일 대상 프로그램의 pid (ps -ef 명령어)]
    # 파이썬 프로그램을 실행하면서 프로파일 할 때
    $ py-spy record -o profile.svg -- python3 numpy_fft_ifft_pyspy.py
    ```
    

![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%207.png)

flame chart의 가로 길이는 전체 프로그램의 실행 시간을 의미, 각 층은 바로 위층 함수 호출한 함수의 실행 시간을 나타냄.

- 사용 방법 2 -  실시간 콜스택 상황 확인

```bash
# 이미 실행 중인 프로그램을 프로파일할 때
$ sudo env "PATH=$PATH" py-spy top --pid [프로파일 대상 프로그램의 pid (ps -ef 명령어)]
# 파이썬 프로그램을 실행하면서 프로파일 할 때
$ py-spy top -- python3 numpy_fft_ifft_pyspy.py
```

![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%208.png)

Own Time: 특정 함수나 코드 블록이 실제로 작업을 수행하는데 소비된 시간으로, 다른 함수를 호출하거나 하위 레벨의 함수에서 사용되는 시간은 포함하지 않음.

Total Time: 특정 함수나 코드 블록이 작업을 수행하는데 소비된 총 시간으로 해당 함수 내에서 호출되는 모든 하위 레벨 함수에서 소요된 시간을 포함함.

# 7. **[Scalene](https://github.com/plasma-umass/scalene): a Python CPU+GPU+memory profiler with AI-powered optimization proposals**

---

- 설치 방법
    
    `$ pip install scalene`
    
- 다른 Python 프로파일러가 할 수 없는 여러 가지 작업을 수행하는 Python용 **고성능 CPU, GPU 및 메모리 프로파일러**로 function-level, line-level 프로파일링 제공
    - Thread, Multiprocessing를 사용하는 코드 프로파일링 가능
    - System Time (I/O, …) 측정 가능
    - 메모리 사용량과 추세 확인 가능
    - memory leak 탐지 가능
- 다른 많은 프로파일러보다 오버헤드가 낮아, 더 빠르게 실행됨.

![출처: [https://github.com/plasma-umass/scalene](https://github.com/plasma-umass/scalene)](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%209.png)

출처: [https://github.com/plasma-umass/scalene](https://github.com/plasma-umass/scalene)

- AI 기반 최적화를 통합한 최초의 프로파일러
- CLI, 웹 기반 GUI 모두 제공

![출처: [https://github.com/plasma-umass/scalene](https://github.com/plasma-umass/scalene)](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%2010.png)

출처: [https://github.com/plasma-umass/scalene](https://github.com/plasma-umass/scalene)

- 사용 방법
    - 유용한 옵션
        
        `--reduced-profile` : 전체 실행 시간 중 1% 이상 실행되거나 적당한 양의 메모리를 할당하는 코드 줄에 대해서만 프로파일을 생성
        
        `--html --outfile [file명].html` : html 결과 저장
        
        `--cpu-only` : CPU만(메모리, … 제외) 프로파일 
        
    - (상세)
        
        ```bash
        scalene your_prog.py                             # full profile (outputs to web interface)
        python3 -m scalene your_prog.py                  # equivalent alternative
        
        scalene --cli your_prog.py                       # use the command-line only (no web interface)
        
        scalene --cpu your_prog.py                       # only profile CPU
        scalene --cpu --gpu your_prog.py                 # only profile CPU and GPU
        scalene --cpu --gpu --memory your_prog.py        # profile everything (same as no options)
        
        scalene --reduced-profile your_prog.py           # only profile lines with significant usage
        scalene --profile-interval 5.0 your_prog.py      # output a new profile every five seconds
        
        scalene (Scalene options) --- your_prog.py (...) # use --- to tell Scalene to ignore options after that point
        scalene --help                                   # lists all options
        ```
        
        ```python
        from scalene import scalene_profiler
        
        # Turn profiling on
        scalene_profiler.start()
        
        # Turn profiling off
        scalene_profiler.stop()
        ```
        
- 프로파일 결과
    - profile.html 파일 저장됨
    - 결과 해석
        - Time
            - Python: 파이썬 코드 수행에 걸린 시간 (많을수록 추가 최적화가 가능함을 의미)
            - native: Numpy와 같은 C/C++로 작성된 라이브러리에서 소요된 시간
            - system: File I/O와 같은 system call에 사용된 시간
        - Memory
            - Python: 파이썬 코드에서 사용하는 메모리
            - native: Numpy와 같은 C 라이브러리에서 사용하는 메모리

![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%2011.png)

![Untitled](%E1%84%80%E1%85%A9%E1%84%89%E1%85%A5%E1%86%BC%E1%84%82%E1%85%B3%E1%86%BC%20%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%84%8A%E1%85%A5%E1%86%AB%20-%20%E1%84%91%E1%85%B3%E1%84%85%E1%85%A9%E1%84%91%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%AF%E1%84%85%E1%85%B5%E1%86%BC%206e501fcbcaa34adfa6406d6ab2a03147/Untitled%2012.png)